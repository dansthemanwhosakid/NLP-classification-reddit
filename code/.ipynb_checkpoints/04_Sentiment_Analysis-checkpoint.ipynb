{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Reddit NLP - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# I really like this color, so it will be used for everything\n",
    "DO = '#7D1B7E'\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the logistic regression classifier returned the best metrics and its top features are interpretable, I am going to investigate the sentiments associated with its top features within the context of the post. I will utilize VADER's sentiment analysis to collect the average positive or negative sentiment metric associated with each feature word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataframe, stop words, train/test split datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_Data_Collection.ipynb         03B_Modeling_Naive_Bayes.ipynb\r\n",
      "02_EDA.ipynb                     03C_Modeling_Random_Forest.ipynb\r\n",
      "03A_Modeling_Log_Reg.ipynb       04_Sentiment_Analysis.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../assets/df.pkl','rb') as f:\n",
    "    df = pickle.load(f)\n",
    "with open('../assets/log_reg_beta.pkl', 'rb') as f:\n",
    "    log_beta = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>dating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The beginning   We have been in a monogamous r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have been together   months  It was a norma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Im a    year old college student  never been o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gf and I both     been dating for   months and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok  some background  Bf and I have been togeth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext  dating\n",
       "0  The beginning   We have been in a monogamous r...       0\n",
       "1  We have been together   months  It was a norma...       0\n",
       "2  Im a    year old college student  never been o...       1\n",
       "3  Gf and I both     been dating for   months and...       0\n",
       "4  Ok  some background  Bf and I have been togeth...       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['selftext','dating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dataframe contains the top words in determining the likelihood of a post being from the dating subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_beta = log_beta[['log_odds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_odds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_words</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>1.519875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dating</th>\n",
       "      <td>1.514506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dates</th>\n",
       "      <td>1.491353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christmas</th>\n",
       "      <td>1.347943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>1.305370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met</th>\n",
       "      <td>1.273777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>1.262360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy</th>\n",
       "      <td>1.252815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interested</th>\n",
       "      <td>1.231349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guys</th>\n",
       "      <td>1.228484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shy</th>\n",
       "      <td>1.218883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apps</th>\n",
       "      <td>1.211925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>1.209031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinder</th>\n",
       "      <td>1.194808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bumble</th>\n",
       "      <td>1.194249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotionally</th>\n",
       "      <td>1.193083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>looking</th>\n",
       "      <td>1.191520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>1.190936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seemed</th>\n",
       "      <td>1.181978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventually</th>\n",
       "      <td>1.181902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             log_odds\n",
       "top_words            \n",
       "date         1.519875\n",
       "dating       1.514506\n",
       "dates        1.491353\n",
       "christmas    1.347943\n",
       "women        1.305370\n",
       "met          1.273777\n",
       "place        1.262360\n",
       "guy          1.252815\n",
       "interested   1.231349\n",
       "guys         1.228484\n",
       "shy          1.218883\n",
       "apps         1.211925\n",
       "girl         1.209031\n",
       "tinder       1.194808\n",
       "bumble       1.194249\n",
       "emotionally  1.193083\n",
       "looking      1.191520\n",
       "single       1.190936\n",
       "seemed       1.181978\n",
       "eventually   1.181902"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_date = log_beta.head(20)\n",
    "top_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dataframe contains the top words in determining the likelihood of a post being from the relationship advice subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_odds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_words</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>my boyfriend</th>\n",
       "      <td>0.703194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my girlfriend</th>\n",
       "      <td>0.796085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>started dating</th>\n",
       "      <td>0.807725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.827784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>argument</th>\n",
       "      <td>0.828984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girlfriend</th>\n",
       "      <td>0.829486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cheating</th>\n",
       "      <td>0.829693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>husband</th>\n",
       "      <td>0.832960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my bf</th>\n",
       "      <td>0.836620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my wife</th>\n",
       "      <td>0.841608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marriage</th>\n",
       "      <td>0.844722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throwaway</th>\n",
       "      <td>0.845702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my husband</th>\n",
       "      <td>0.845994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advice</th>\n",
       "      <td>0.847282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>0.850350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>together</th>\n",
       "      <td>0.852991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wife</th>\n",
       "      <td>0.853068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bf</th>\n",
       "      <td>0.856477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worried</th>\n",
       "      <td>0.861942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurt</th>\n",
       "      <td>0.864772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                log_odds\n",
       "top_words               \n",
       "my boyfriend    0.703194\n",
       "my girlfriend   0.796085\n",
       "started dating  0.807725\n",
       "sex             0.827784\n",
       "argument        0.828984\n",
       "girlfriend      0.829486\n",
       "cheating        0.829693\n",
       "husband         0.832960\n",
       "my bf           0.836620\n",
       "my wife         0.841608\n",
       "marriage        0.844722\n",
       "throwaway       0.845702\n",
       "my husband      0.845994\n",
       "advice          0.847282\n",
       "help            0.850350\n",
       "together        0.852991\n",
       "wife            0.853068\n",
       "bf              0.856477\n",
       "worried         0.861942\n",
       "hurt            0.864772"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_relationship = log_beta.tail(20).sort_values('log_odds')\n",
    "top_relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to instantiate the Sentiment Intensity Analyzer and it will return 4 sentiment metrics when it is applied to each post:\n",
    "\n",
    "`compound` - ranges between -1 (most extreme negative) to +1 (most extreme positive\n",
    "\n",
    "\n",
    "`positive` - a percentage rating of how positive a post is \n",
    "\n",
    "\n",
    "`neutral` - a percentage rating of how neutral a post is \n",
    "\n",
    "\n",
    "`negative` - a percentage rating of how negative a post is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.str.contains('t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I WANT HIGHEST POS \n",
    " I WANT LOWEST NEG\n",
    " I WANT TOTAL CCOUNT OF POSTS\n",
    " I WANT AVERAGE METRICS\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [1,2,3]\n",
    "z.append(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_steroids():\n",
    "    \n",
    "    post_counter = 0\n",
    "    \n",
    "    negative_scores = []\n",
    "    neutral_scores = []\n",
    "    positive_scores = []\n",
    "    compound_scores = []\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    print('Which subreddit do you want?')\n",
    "    subreddit = input(\"You can choose either 'dating' or 'relationship_advice': \")\n",
    "    \n",
    "    if subreddit == 'dating':\n",
    "        \n",
    "        print(\"\\nThe top dating words are:\")\n",
    "        print(list(top_date.index))\n",
    "        \n",
    "        word = input(\"\\nWhich word do you want to perform sentiment analysis on? \")\n",
    "        \n",
    "        for post in df[df['dating'] == 1]['selftext'].values[:]:\n",
    "            if word in post:\n",
    "                \n",
    "                post_counter += 1\n",
    "                \n",
    "                compound_scores.append(sia.polarity_scores(post)['compound'])\n",
    "                positive_scores.append(sia.polarity_scores(post)['pos'])\n",
    "                neutral_scores.append(sia.polarity_scores(post)['neu'])\n",
    "                negative_scores.append(sia.polarity_scores(post)['neg'])\n",
    "                \n",
    "    elif subreddit == 'relationship_advice':\n",
    "        \n",
    "        print(\"\\nThe top relationship_advice words are:\")\n",
    "        print(list(top_relationship.index))\n",
    "        \n",
    "        word = input(\"\\nWhich word do you want to perform sentiment analysis on? \")\n",
    "        \n",
    "        for post in df[df['dating'] == 1]['selftext'].values[:]:\n",
    "            if word in post:\n",
    "                \n",
    "                post_counter += 1\n",
    "                \n",
    "                compound_scores.append(sia.polarity_scores(post)['compound'])\n",
    "                positive_scores.append(sia.polarity_scores(post)['pos'])\n",
    "                neutral_scores.append(sia.polarity_scores(post)['neu'])\n",
    "                negative_scores.append(sia.polarity_scores(post)['neg'])       \n",
    "            \n",
    "    if subreddit == 'dating':\n",
    "        percentage = round(post_counter/len(df[df['dating'] == 1]),2)\n",
    "    \n",
    "    elif subreddit == 'relationship_advice':\n",
    "        percentage = round(post_counter/len(df[df['dating'] == 0]),2)\n",
    "    \n",
    "    print(f\"\\n{post_counter} posts in the {subreddit} subreddit contain the word '{word}'\")\n",
    "    print(f\"\\n{percentage} of the posts in the {subreddit} subreddit contain the word '{word}'\")\n",
    "    \n",
    "    sentiment_dict = {'Average Compound': round(np.mean(compound_scores),2),\n",
    "                      'Average Positive': round(np.mean(positive_scores),2),\n",
    "                      'Average Neutral': round(np.mean(neutral_scores),2),\n",
    "                      'Average Negative': round(np.mean(negative_scores),2)\n",
    "                     }\n",
    "\n",
    "    print(f'\\nThe sentiment metrics for the word {word}:\\n{sentiment_dict}')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which subreddit do you want?\n",
      "You can choose either 'dating' or 'relationship_advice': dating\n",
      "\n",
      "The top dating words are:\n",
      "['date', 'dating', 'dates', 'christmas', 'women', 'met', 'place', 'guy', 'interested', 'guys', 'shy', 'apps', 'girl', 'tinder', 'bumble', 'emotionally', 'looking', 'single', 'seemed', 'eventually']\n",
      "\n",
      "Which word do you want to perform sentiment analysis on? shy\n",
      "\n",
      "399 posts in the dating subreddit contain the word 'shy'\n",
      "\n",
      "0.05 of the posts in the dating subreddit contain the word 'shy'\n",
      "\n",
      "The sentiment metrics for the word shy:\n",
      "{'Average Compound': 0.59, 'Average Positive': 0.15, 'Average Neutral': 0.76, 'Average Negative': 0.09}\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer_steroids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
